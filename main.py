import os
import requests
import json
import re
import time
from google import genai
from google.genai import types
from datetime import datetime, timedelta

# í™˜ê²½ ì„¤ì •
NAVER_ID = os.environ['NAVER_CLIENT_ID']
NAVER_SECRET = os.environ['NAVER_CLIENT_SECRET']
client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])
MODEL_NAME = 'gemini-2.0-flash'

# [ì¶”ê°€] ê³µí†µ ì‹œìŠ¤í…œ ì§€ì¹¨: ëª¨ë¸ì˜ íƒœë„ë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
SYSTEM_INSTRUCTION = """
ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ë° ë°ì´í„° ì²˜ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
1. ëª¨ë“  ë‹µë³€ì€ ì„œë¡ , ê²°ë¡ , 'ì•Œê² ìŠµë‹ˆë‹¤' ê°™ì€ ì¸ì‚¬ë§ ì—†ì´ 'ë³¸ë¡ 'ë§Œ ì¦‰ì‹œ ì¶œë ¥í•©ë‹ˆë‹¤.
2. ìš”ì•½ ìš”ì²­ ì‹œ ë°˜ë“œì‹œ í•œêµ­ì–´ 3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.
3. ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•Œ 'ê²€ìƒ‰í•˜ê² ìŠµë‹ˆë‹¤'ë¼ëŠ” ë§ì„ ì ˆëŒ€ ë‚´ë±‰ì§€ ë§ˆì„¸ìš”. ê²°ê³¼ë§Œ ë³´ì—¬ì£¼ì„¸ìš”.
"""

def get_24h_news():
    """1ë‹¨ê³„: 24ì‹œê°„ ë‚´ ë‰´ìŠ¤ ì œëª©ë“¤ë§Œ ìˆ˜ì§‘"""
    print(">>> [1ë‹¨ê³„] ë„¤ì´ë²„ ë‰´ìŠ¤ ì œëª© ìˆ˜ì§‘ ì¤‘...")
    query = "AI OR ai OR ì¸ê³µì§€ëŠ¥"
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=100&sort=date"
    headers = {"X-Naver-Client-Id": NAVER_ID, "X-Naver-Client-Secret": NAVER_SECRET}
    
    try:
        response = requests.get(url, headers=headers)
        items = response.json().get('items', [])
        now_kst = datetime.utcnow() + timedelta(hours=9)
        filtered = []
        
        for item in items:
            pub_date = datetime.strptime(item['pubDate'][:-6], "%a, %d %b %Y %H:%M:%S")
            if now_kst - pub_date <= timedelta(hours=24):
                clean_title = re.sub(r'<[^>]*>', '', item['title'])
                filtered.append({"title": clean_title, "link": item['link']})
        
        print(f">>> {len(filtered)}ê°œì˜ í›„ë³´ ì œëª© í™•ë³´.")
        return filtered
    except: return []

def analyze_and_publish():
    news_pool = get_24h_news()
    if not news_pool: return

    # 2~3ë‹¨ê³„: ì¤‘ë³µ ì œê±° ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    print(">>> [2-3ë‹¨ê³„] AI ì¤‘ë³µ ì œê±° ë° ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...")
    process_prompt = f"""
    ì•„ë˜ ë‰´ìŠ¤ ì œëª© ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´:
    1. ë™ì¼í•œ ì‚¬ê±´ì„ ë‹¤ë£¨ëŠ” ì¤‘ë³µ ì œëª©ì€ í•˜ë‚˜ë§Œ ë‚¨ê¸°ê³  ì œê±°í•´.
    2. ë‚¨ì€ ê³ ìœ  ê¸°ì‚¬ë“¤ì„ [ê²½ì œ, ì‚¬íšŒ, ìƒí™œ&ë¬¸í™”, ì‚°ì—…, ì •ì¹˜, it&ê³¼í•™, í•´ì™¸] ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•´.
    3. ë°˜ë“œì‹œ ìˆœìˆ˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´. ì˜ˆ: {{"ê²½ì œ": [{"title": "ì œëª©", "link": "ë§í¬"}]}}
    ë°ì´í„°: {news_pool}
    """
    
    try:
        res = client.models.generate_content(
            model=MODEL_NAME, 
            contents=process_prompt,
            config=types.GenerateContentConfig(system_instruction=SYSTEM_INSTRUCTION)
        )
        # JSONë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•œ ì •ê·œì‹
        json_match = re.search(r'\{.*\}', res.text, re.DOTALL)
        category_map = json.loads(json_match.group())
    except Exception as e:
        print(f"!!! ì¤‘ë³µ ì œê±° ë° ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return

    final_html_body = ""

    # 4ë‹¨ê³„: ê°œë³„ ê¸°ì‚¬ ì •ë… ë° ë¶„ì„
    for category, items in category_map.items():
        if not items: continue
        print(f">>> [{category}] ë¶„ì•¼ ë¶„ì„ ì‹œì‘...")
        unique_articles = []
        
        for item in items[:5]: # RPM ì œí•œì„ ê³ ë ¤í•´ ì¹´í…Œê³ ë¦¬ë‹¹ 5ê°œ ì œí•œ
            link = item.get('link')
            # [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ë¥¼ ë” ì—„ê²©í•˜ê²Œ ë³€ê²½
            reading_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ë§í¬ì˜ ë³¸ë¬¸ì„ ì •ë…í•˜ê³  í•œêµ­ì–´ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ ì„¤ëª…ì€ ìƒëµí•˜ì‹­ì‹œì˜¤: {link}"
            
            try:
                time.sleep(4) # Rate Limit ë°©ì§€
                
                response = client.models.generate_content(
                    model=MODEL_NAME,
                    contents=reading_prompt,
                    config=types.GenerateContentConfig(
                        system_instruction=SYSTEM_INSTRUCTION, # ì‹œìŠ¤í…œ ì§€ì¹¨ ì¬ê°•ì¡°
                        tools=[types.Tool(google_search=types.GoogleSearch())]
                    )
                )
                
                # [ìˆ˜ì •] ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸í•˜ê³  ì •ì œ
                summary = response.text.strip()
                if not summary or "ìš”ì•½í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤" in summary:
                    # ê°€ë” ê²€ìƒ‰ ë¡œê·¸ë§Œ ë‚¨ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í…ìŠ¤íŠ¸ íŒŒíŠ¸ ì¬í™•ì¸
                    summary = "ê¸°ì‚¬ ë‚´ìš©ì„ ë¶„ì„í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. (ê²€ìƒ‰ ê²°ê³¼ ë¯¸ë„ë‹¬)"

                unique_articles.append({
                    "title": item.get('title'),
                    "link": link,
                    "summary": summary.replace('\n', '<br>')
                })
                print(f"   + ë¶„ì„ ì™„ë£Œ: {item.get('title')[:15]}...")
            except Exception as e:
                print(f"   - ì •ë… ì‹¤íŒ¨: {e}")
                continue

        if unique_articles:
            final_html_body += f"<section><h2>[{category}]</h2><ul>"
            for a in unique_articles:
                final_html_body += f"<li><a href='{a['link']}' target='_blank'><strong>{a['title']}</strong></a><p>{a['summary']}</p></li>"
            final_html_body += "</ul></section><hr>"

    # HTML ì €ì¥
    update_time = (datetime.utcnow() + timedelta(hours=9)).strftime('%Y-%m-%d %H:%M')
    html_template = f"""
    <html>
    <body style='font-family: sans-serif; padding: 40px; line-height: 1.6; max-width: 800px; margin: auto;'>
        <div style='color: #666;'>{update_time} KST</div>
        <h1 style='border-bottom: 2px solid #333;'>ğŸ¤– AI ë‰´ìŠ¤ ì •ë… ë¦¬í¬íŠ¸</h1>
        {final_html_body}
    </body>
    </html>
    """
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_template)
    print(">>> [ì™„ë£Œ] ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ.")

if __name__ == "__main__":
    analyze_and_publish()
