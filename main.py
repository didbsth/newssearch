import os
import requests
import json
import re
from google import genai
from google.genai import types # ë„êµ¬ ì„¤ì •ì„ ìœ„í•´ ì¶”ê°€
from datetime import datetime, timedelta

# 1. í™˜ê²½ ì„¤ì • ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
NAVER_ID = os.environ['NAVER_CLIENT_ID']
NAVER_SECRET = os.environ['NAVER_CLIENT_SECRET']
client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])
MODEL_NAME = 'gemini-2.0-flash' # ì •ë… ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ìµœì‹  ëª¨ë¸ ê¶Œì¥

def get_24h_news():
    """1ë‹¨ê³„: ë„¤ì´ë²„ APIë¥¼ í†µí•´ ë‰´ìŠ¤ ëª©ë¡ ìˆ˜ì§‘ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
    print(">>> [1ë‹¨ê³„] ë„¤ì´ë²„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ìˆ˜ì§‘ ì¤‘...")
    query = "AI OR ai OR ì¸ê³µì§€ëŠ¥"
    url = f"https://openapi.naver.com/v1/search/news.json?query={query}&display=100&sort=date"
    headers = {"X-Naver-Client-Id": NAVER_ID, "X-Naver-Client-Secret": NAVER_SECRET}
    
    try:
        response = requests.get(url, headers=headers)
        res_data = response.json().get('items', [])
        now_kst = datetime.utcnow() + timedelta(hours=9)
        filtered_news = []
        
        for item in res_data:
            try:
                pub_date = datetime.strptime(item['pubDate'][:-6], "%a, %d %b %Y %H:%M:%S")
                if now_kst - pub_date <= timedelta(hours=24):
                    item['title'] = re.sub(r'<[^>]*>', '', item['title'])
                    filtered_news.append(item)
            except: continue
        
        print(f">>> {len(filtered_news)}ê°œì˜ ìµœì‹  ê¸°ì‚¬ í™•ë³´ ì™„ë£Œ.")
        return filtered_news
    except Exception as e:
        print(f"!!! ë‰´ìŠ¤ ìˆ˜ì§‘ ì—ëŸ¬: {e}")
        return []

def analyze_and_publish():
    news_pool = get_24h_news()
    if not news_pool: return

    # [2ë‹¨ê³„] ë¶„ë¥˜ (Geminiì—ê²Œ ëª©ë¡ ì „ë‹¬)
    print(">>> [2ë‹¨ê³„] ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì¤‘...")
    classification_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ ê²½ì œ, ì‚¬íšŒ, ìƒí™œ&ë¬¸í™”, ì‚°ì—…, ì •ì¹˜, it&ê³¼í•™, í•´ì™¸ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”: {news_pool}"
    
    res = client.models.generate_content(model=MODEL_NAME, contents=classification_prompt)
    try:
        json_match = re.search(r'\{.*\}', res.text, re.DOTALL)
        category_map = json.loads(json_match.group())
    except: return

    final_html_body = ""

    # [3ë‹¨ê³„] êµ¬ê¸€ ì¸í”„ë¼ë¥¼ ì´ìš©í•œ ê¸°ì‚¬ ì „ë¬¸ ì •ë… ë° ë¶„ì„
    for category, items in category_map.items():
        print(f">>> [{category}] ë¶„ì•¼ ê¸°ì‚¬ ì •ë… ì‹œì‘...")
        unique_articles = []
        
        for item in items[:5]: # ê° ë¶„ì•¼ ìƒìœ„ 5ê°œ ë¶„ì„
            link = item.get('link')
            
            # [í•µì‹¬] Geminiì—ê²Œ êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ ë§í¬ë¥¼ ì •ë…í•˜ë¼ê³  ì§€ì‹œí•©ë‹ˆë‹¤.
            # ì´ ëª…ë ¹ì€ ì‚¬ì´íŠ¸ì˜ ë°©ì–´ë²½ì„ ìš°íšŒí•˜ì—¬ ë³¸ë¬¸ ì „ì²´ë¥¼ íŒŒì•…í•˜ê²Œ í•©ë‹ˆë‹¤.
            reading_prompt = f"""
            ë‹¤ìŒ ë‰´ìŠ¤ ë§í¬ì— ì ‘ì†í•˜ì—¬ ê¸°ì‚¬ì˜ 'ì „ì²´ ë³¸ë¬¸'ì„ ì •ë…í•œ í›„ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.
            ë§í¬: {link}
            
            ìš”êµ¬ì‚¬í•­:
            1. ì›¹ì‚¬ì´íŠ¸ ë©”ë‰´ë‚˜ ê´‘ê³  ì •ë³´ëŠ” ë¬´ì‹œí•˜ê³  ê¸°ì‚¬ ë‚´ìš©ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”.
            2. ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ 3~4ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
            """
            
            try:
                # google_search ë„êµ¬ë¥¼ í™œì„±í™”í•˜ì—¬ í˜¸ì¶œ
                response = client.models.generate_content(
                    model=MODEL_NAME,
                    contents=reading_prompt,
                    config=types.GenerateContentConfig(
                        tools=[types.Tool(google_search=types.GoogleSearch())]
                    )
                )
                
                analysis_text = response.text
                unique_articles.append({
                    "title": item.get('title'),
                    "link": link,
                    "summary": analysis_text.replace('\n', '<br>')
                })
                print(f"   + ì •ë… ì™„ë£Œ: {item.get('title')[:15]}...")
            except Exception as e:
                print(f"   - ì •ë… ì‹¤íŒ¨ ({item.get('title')[:10]}): {e}")
                continue

        if unique_articles:
            final_html_body += f"<section><h2>[{category}] ì£¼ìš” ë‰´ìŠ¤</h2><ul>"
            for a in unique_articles:
                final_html_body += f"<li><a href='{a['link']}' target='_blank'><strong>{a['title']}</strong></a><p>{a['summary']}</p></li>"
            final_html_body += "</ul></section><hr>"

    # 4ë‹¨ê³„: HTML ìƒì„± ë° ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
    update_time = (datetime.utcnow() + timedelta(hours=9)).strftime('%Y-%m-%d %H:%M')
    html_template = f"<html><body style='font-family:sans-serif; padding:40px;'><div>{update_time} KST</div><h1>ğŸ¤– AI ë‰´ìŠ¤ ì •ë… ë¦¬í¬íŠ¸</h1>{final_html_body}</body></html>"
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_template)
    print(">>> [ì™„ë£Œ] êµ¬ê¸€ ì¸í”„ë¼ ê¸°ë°˜ ë¦¬í¬íŠ¸ ìƒì„± ì„±ê³µ.")

if __name__ == "__main__":
    analyze_and_publish()
